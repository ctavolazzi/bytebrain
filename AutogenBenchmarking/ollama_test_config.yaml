# Ollama Test Configuration
api:
  base_url: "http://localhost:11434"
  version: "v1"

models:
  - name: "wizardlm2"
    description: "WizardLM 2 model"
    test_cases:
      - name: "basic_math"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is 2+2?"
      - name: "knowledge_query"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is the capital of France?"

  - name: "nemotron-mini"
    description: "Nemotron Mini model"
    test_cases:
      - name: "basic_math"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is 2+2?"
      - name: "knowledge_query"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is the capital of France?"

  - name: "llama3.2"
    description: "Llama 3.2 model"
    test_cases:
      - name: "basic_math"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is 2+2?"
      - name: "knowledge_query"
        messages:
          - role: "system"
            content: "You are a helpful assistant."
          - role: "user"
            content: "What is the capital of France?"

test_options:
  stream: true
  temperature: 0.7
  max_tokens: 500